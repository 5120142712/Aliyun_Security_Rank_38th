{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三届阿里云安全大赛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 因为数据序列有点长，每个pid最长有5000个调用序列，所以一开始接触赛题的时候还是想用TF-IDF这种比较传统比较快的特征提取做法来试一下。\n",
    "- 特征主要包括三部分：① 一些手动的统计特征，比如最常出现的api名字的调用比例和数量、不同返回值的数量比例等。②TF-IDF特征，将调用序列看成文本，计算词频逆词频。③Doc2Vec特征，用训练好的doc2vec向量进行聚类，统计不同类别的数量及特则。\n",
    "- 由于只花了一个星期来做这道题，而这一个星期也是心不在焉....所以很多东西没有时间去试一下，比如FB的fasttext。深度模型也是简单做一个RNN....\n",
    "- 最后排名是38/622....还得继续努力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_data = pd.read_csv('input/train.csv')\n",
    "\n",
    "test = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>api</th>\n",
       "      <th>tid</th>\n",
       "      <th>return_value</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GetSystemTimeAsFileTime</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtFreeVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NtAllocateVirtualMemory</td>\n",
       "      <td>2644</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label                      api   tid  return_value  index\n",
       "0        0      0  GetSystemTimeAsFileTime  2644             0      0\n",
       "1        0      0  NtAllocateVirtualMemory  2644             0      1\n",
       "2        0      0      NtFreeVirtualMemory  2644             0      2\n",
       "3        0      0  NtAllocateVirtualMemory  2644             0      3\n",
       "4        0      0  NtAllocateVirtualMemory  2644             0      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建特征DF\n",
    "df_train = train_data.groupby('file_id').label.agg('first').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing_stat_fea(df, data, col):\n",
    "    # 一些统计特征\n",
    "    df = pd.merge(df, data[['file_id', col]].groupby(['file_id'])[col].nunique().reset_index().rename(columns={col: 'nunique_'+col}), on='file_id', how='left')\n",
    "\n",
    "    t = data[['file_id', col]]\n",
    "    t['num'] = 1\n",
    "    t = t.groupby(['file_id', col]).num.agg('sum').reset_index()\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.agg('mean').reset_index().rename(columns={'num': 'mean_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.agg('max').reset_index().rename(columns={'num': 'max_num_'+col}),on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.agg('min').reset_index().rename(columns={'num': 'min_num_'+col}),on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.agg('var').reset_index().rename(columns={'num': 'var_num_'+col}),on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.agg('skew').reset_index().rename(columns={'num': 'skew_num_'+col}),on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).num.apply(stats.kurtosis).reset_index().rename(columns={'num': 'kurt_num_'+col}),on='file_id', how='left')\n",
    "    df['max_min_'+col] = df['max_num_'+col] - df['min_num_'+col]\n",
    "\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().mean()).reset_index().rename(columns={0: 'diff_mean_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().max()).reset_index().rename(columns={0: 'diff_max_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().min()).reset_index().rename(columns={0: 'diff_min_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().var()).reset_index().rename(columns={0: 'diff_var_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().skew()).reset_index().rename(columns={0: 'diff_skew_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().kurt()).reset_index().rename(columns={0: 'diff_kurt_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().mad()).reset_index().rename(columns={0: 'diff_mad_num_'+col}), on='file_id', how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().max()-x['num'].sort_values().diff().min()).reset_index().rename(columns={0:'diff_seq_max_gap_min_num_'+col}),on=['file_id'],how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().diff().min()).reset_index().rename(columns={0:'diff2_min_gap_num_'+col}),on=['file_id'],how='left')\n",
    "    df = pd.merge(df, t.groupby(['file_id']).apply(lambda x:x['num'].diff().diff().max()).reset_index().rename(columns={0:'diff2_max_gap_num_'+col}),on=['file_id'],how='left')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, train_data[['file_id']].groupby(['file_id']).size().reset_index().rename(columns={0: 'num_invoke'}), on='file_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cluster/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train = processing_stat_fea(df_train, train_data, 'api')\n",
    "df_train = processing_stat_fea(df_train, train_data, 'tid')\n",
    "df_train = processing_stat_fea(df_train, train_data, 'return_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>num_invoke</th>\n",
       "      <th>nunique_api</th>\n",
       "      <th>mean_num_api</th>\n",
       "      <th>max_num_api</th>\n",
       "      <th>min_num_api</th>\n",
       "      <th>var_num_api</th>\n",
       "      <th>skew_num_api</th>\n",
       "      <th>kurt_num_api</th>\n",
       "      <th>...</th>\n",
       "      <th>diff_mean_num_return_value</th>\n",
       "      <th>diff_max_num_return_value</th>\n",
       "      <th>diff_min_num_return_value</th>\n",
       "      <th>diff_var_num_return_value</th>\n",
       "      <th>diff_skew_num_return_value</th>\n",
       "      <th>diff_kurt_num_return_value</th>\n",
       "      <th>diff_mad_num_return_value</th>\n",
       "      <th>diff_seq_max_gap_min_num_return_value</th>\n",
       "      <th>diff2_min_gap_num_return_value</th>\n",
       "      <th>diff2_max_gap_num_return_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "      <td>22.315789</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>708.672515</td>\n",
       "      <td>1.346982</td>\n",
       "      <td>1.368728</td>\n",
       "      <td>...</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-338.0</td>\n",
       "      <td>58225.800000</td>\n",
       "      <td>-0.290972</td>\n",
       "      <td>1.736859</td>\n",
       "      <td>153.120000</td>\n",
       "      <td>338.0</td>\n",
       "      <td>-676.0</td>\n",
       "      <td>412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.352381</td>\n",
       "      <td>3.444457</td>\n",
       "      <td>8.277387</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>-2.213827</td>\n",
       "      <td>4.920589</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "      <td>43.076923</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "      <td>37224.415865</td>\n",
       "      <td>5.516723</td>\n",
       "      <td>27.213945</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.531915</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1162.0</td>\n",
       "      <td>14604.961336</td>\n",
       "      <td>-9.421704</td>\n",
       "      <td>90.143352</td>\n",
       "      <td>28.082390</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-1002.0</td>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "      <td>87.589744</td>\n",
       "      <td>2970</td>\n",
       "      <td>1</td>\n",
       "      <td>157324.063270</td>\n",
       "      <td>6.093128</td>\n",
       "      <td>37.151675</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.782895</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-4086.0</td>\n",
       "      <td>136949.601560</td>\n",
       "      <td>-7.860359</td>\n",
       "      <td>104.019402</td>\n",
       "      <td>54.901575</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>-6086.0</td>\n",
       "      <td>4064.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  num_invoke  nunique_api  mean_num_api  max_num_api  \\\n",
       "0        0      0         424           19     22.315789           99   \n",
       "1        1      5           2            2      1.000000            1   \n",
       "2        2      5          34           15      2.266667           14   \n",
       "3        3      5        2800           65     43.076923         1128   \n",
       "4        4      5        6832           78     87.589744         2970   \n",
       "\n",
       "   min_num_api    var_num_api  skew_num_api  kurt_num_api  \\\n",
       "0            1     708.672515      1.346982      1.368728   \n",
       "1            1       0.000000           NaN     -3.000000   \n",
       "2            1      11.352381      3.444457      8.277387   \n",
       "3            1   37224.415865      5.516723     27.213945   \n",
       "4            1  157324.063270      6.093128     37.151675   \n",
       "\n",
       "                ...                diff_mean_num_return_value  \\\n",
       "0               ...                                 14.600000   \n",
       "1               ...                                       NaN   \n",
       "2               ...                                 -5.000000   \n",
       "3               ...                                -14.531915   \n",
       "4               ...                                -13.782895   \n",
       "\n",
       "   diff_max_num_return_value  diff_min_num_return_value  \\\n",
       "0                      338.0                     -338.0   \n",
       "1                        NaN                        NaN   \n",
       "2                        1.0                      -25.0   \n",
       "3                       15.0                    -1162.0   \n",
       "4                     2000.0                    -4086.0   \n",
       "\n",
       "   diff_var_num_return_value  diff_skew_num_return_value  \\\n",
       "0               58225.800000                   -0.290972   \n",
       "1                        NaN                         NaN   \n",
       "2                 125.500000                   -2.213827   \n",
       "3               14604.961336                   -9.421704   \n",
       "4              136949.601560                   -7.860359   \n",
       "\n",
       "   diff_kurt_num_return_value  diff_mad_num_return_value  \\\n",
       "0                    1.736859                 153.120000   \n",
       "1                         NaN                        NaN   \n",
       "2                    4.920589                   8.000000   \n",
       "3                   90.143352                  28.082390   \n",
       "4                  104.019402                  54.901575   \n",
       "\n",
       "   diff_seq_max_gap_min_num_return_value  diff2_min_gap_num_return_value  \\\n",
       "0                                  338.0                          -676.0   \n",
       "1                                    NaN                             NaN   \n",
       "2                                    1.0                             0.0   \n",
       "3                                   15.0                         -1002.0   \n",
       "4                                 2000.0                         -6086.0   \n",
       "\n",
       "   diff2_max_gap_num_return_value  \n",
       "0                           412.0  \n",
       "1                             NaN  \n",
       "2                            24.0  \n",
       "3                          1122.0  \n",
       "4                          4064.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processing_return_value(df, data):\n",
    "    # 先针对0跟1\n",
    "    df = pd.merge(df, train_data[\n",
    "        train_data.return_value == 0][['file_id', 'return_value']\n",
    "                                     ].groupby('file_id').size().reset_index().rename(columns={0: 'num_0_ret_val'}), \n",
    "                  on='file_id', how='left')\n",
    "    df = pd.merge(df, train_data[\n",
    "        train_data.return_value == 1][['file_id', 'return_value']\n",
    "                                     ].groupby('file_id').size().reset_index().rename(columns={0: 'num_1_ret_val'}), \n",
    "                  on='file_id', how='left')    \n",
    "    # 正负值\n",
    "    df = pd.merge(df, train_data[\n",
    "        train_data.return_value > 1][['file_id', 'return_value']\n",
    "                                 ].groupby('file_id').size().reset_index().rename(columns={0: 'num_pos_ret_val'}), \n",
    "              on='file_id', how='left')   \n",
    "    df = pd.merge(df, train_data[\n",
    "        train_data.return_value < 0][['file_id', 'return_value']\n",
    "                                 ].groupby('file_id').size().reset_index().rename(columns={0: 'num_neg_ret_val'}), \n",
    "              on='file_id', how='left')   \n",
    "    \n",
    "    df['ret_val_0_ratio'] = df['num_0_ret_val'] / df['num_invoke']\n",
    "    df['ret_val_1_ratio'] = df['num_1_ret_val'] / df['num_invoke']\n",
    "    df['ret_val_pos_ratio'] = df['num_pos_ret_val'] / df['num_invoke']\n",
    "    df['ret_val_neg_ratio'] = df['num_neg_ret_val'] / df['num_invoke']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = processing_return_value(df_train, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>num_invoke</th>\n",
       "      <th>nunique_api</th>\n",
       "      <th>mean_num_api</th>\n",
       "      <th>max_num_api</th>\n",
       "      <th>min_num_api</th>\n",
       "      <th>var_num_api</th>\n",
       "      <th>skew_num_api</th>\n",
       "      <th>kurt_num_api</th>\n",
       "      <th>...</th>\n",
       "      <th>diff2_min_gap_num_return_value</th>\n",
       "      <th>diff2_max_gap_num_return_value</th>\n",
       "      <th>num_0_ret_val</th>\n",
       "      <th>num_1_ret_val</th>\n",
       "      <th>num_pos_ret_val</th>\n",
       "      <th>num_neg_ret_val</th>\n",
       "      <th>ret_val_0_ratio</th>\n",
       "      <th>ret_val_1_ratio</th>\n",
       "      <th>ret_val_pos_ratio</th>\n",
       "      <th>ret_val_neg_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "      <td>22.315789</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>708.672515</td>\n",
       "      <td>1.346982</td>\n",
       "      <td>1.368728</td>\n",
       "      <td>...</td>\n",
       "      <td>-676.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183962</td>\n",
       "      <td>0.014151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.352381</td>\n",
       "      <td>3.444457</td>\n",
       "      <td>8.277387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "      <td>43.076923</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "      <td>37224.415865</td>\n",
       "      <td>5.516723</td>\n",
       "      <td>27.213945</td>\n",
       "      <td>...</td>\n",
       "      <td>-1002.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488571</td>\n",
       "      <td>0.431429</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "      <td>87.589744</td>\n",
       "      <td>2970</td>\n",
       "      <td>1</td>\n",
       "      <td>157324.063270</td>\n",
       "      <td>6.093128</td>\n",
       "      <td>37.151675</td>\n",
       "      <td>...</td>\n",
       "      <td>-6086.0</td>\n",
       "      <td>4064.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>4120.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310304</td>\n",
       "      <td>0.603044</td>\n",
       "      <td>0.086651</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  num_invoke  nunique_api  mean_num_api  max_num_api  \\\n",
       "0        0      0         424           19     22.315789           99   \n",
       "1        1      5           2            2      1.000000            1   \n",
       "2        2      5          34           15      2.266667           14   \n",
       "3        3      5        2800           65     43.076923         1128   \n",
       "4        4      5        6832           78     87.589744         2970   \n",
       "\n",
       "   min_num_api    var_num_api  skew_num_api  kurt_num_api        ...          \\\n",
       "0            1     708.672515      1.346982      1.368728        ...           \n",
       "1            1       0.000000           NaN     -3.000000        ...           \n",
       "2            1      11.352381      3.444457      8.277387        ...           \n",
       "3            1   37224.415865      5.516723     27.213945        ...           \n",
       "4            1  157324.063270      6.093128     37.151675        ...           \n",
       "\n",
       "   diff2_min_gap_num_return_value  diff2_max_gap_num_return_value  \\\n",
       "0                          -676.0                           412.0   \n",
       "1                             NaN                             NaN   \n",
       "2                             0.0                            24.0   \n",
       "3                         -1002.0                          1122.0   \n",
       "4                         -6086.0                          4064.0   \n",
       "\n",
       "   num_0_ret_val  num_1_ret_val  num_pos_ret_val  num_neg_ret_val  \\\n",
       "0          340.0            NaN             78.0              6.0   \n",
       "1            2.0            NaN              NaN              NaN   \n",
       "2           27.0            NaN              7.0              NaN   \n",
       "3         1368.0         1208.0            224.0              NaN   \n",
       "4         2120.0         4120.0            592.0              NaN   \n",
       "\n",
       "   ret_val_0_ratio  ret_val_1_ratio  ret_val_pos_ratio  ret_val_neg_ratio  \n",
       "0         0.801887              NaN           0.183962           0.014151  \n",
       "1         1.000000              NaN                NaN                NaN  \n",
       "2         0.794118              NaN           0.205882                NaN  \n",
       "3         0.488571         0.431429           0.080000                NaN  \n",
       "4         0.310304         0.603044           0.086651                NaN  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lx(df, data, col):\n",
    "        # 连续登陆 最大 最小 平均 方差\n",
    "    def checknum(v):\n",
    "        #计算列表中连续=n的数目，返回最大连续数\n",
    "        val = v.values\n",
    "        res=[]\n",
    "        count=1\n",
    "        for i in range(len(val) - 1):\n",
    "            if val[i+1] == val[i]:\n",
    "                count += 1\n",
    "            else:\n",
    "                res.append(count)\n",
    "                count = 1\n",
    "        res.append(count)\n",
    "        ret = pd.Series()\n",
    "        if len(res) == 0:\n",
    "            ret['mean_lx_'+col] = np.NaN\n",
    "            ret['var_lx_'+col] = np.NaN\n",
    "            ret['max_lx_'+col] = np.NaN\n",
    "            ret['min_lx_'+col] = np.NaN\n",
    "            ret['skew_lx_'+col] = np.NaN\n",
    "            ret['kurt_lx_'+col] = np.NaN\n",
    "            ret['mean_diff_lx_'+col] = np.NaN\n",
    "            ret['var_diff_lx_'+col] = np.NaN\n",
    "            ret['max_diff_lx_'+col] = np.NaN\n",
    "            ret['min_diff_lx_'+col] = np.NaN\n",
    "            ret['skew_diff_lx_'+col] = np.NaN\n",
    "            ret['kurt_diff_lx_'+col] = np.NaN\n",
    "            return ret\n",
    "        ret['mean_lx_'+col] = np.mean(res)\n",
    "        ret['var_lx_'+col] = np.var(res)\n",
    "        ret['max_lx_'+col] = np.max(res)\n",
    "        ret['min_lx_'+col] = np.min(res)\n",
    "        ret['skew_lx_'+col] =  stats.skew(res)\n",
    "        ret['kurt_lx_'+col] = stats.kurtosis(res)    \n",
    "        diff_res = np.diff(res)            \n",
    "        if len(diff_res) == 0:\n",
    "            ret['mean_diff_lx_'+col] = np.NaN\n",
    "            ret['var_diff_lx_'+col] = np.NaN\n",
    "            ret['max_diff_lx_'+col] = np.NaN\n",
    "            ret['min_diff_lx_'+col] = np.NaN\n",
    "            ret['skew_diff_lx_'+col] = np.NaN\n",
    "            ret['kurt_diff_lx_'+col] = np.NaN\n",
    "            return ret\n",
    "        ret['mean_diff_lx_'+col] = np.mean(diff_res)\n",
    "        ret['var_diff_lx_'+col] = np.var(diff_res)\n",
    "        ret['max_diff_lx_'+col] = np.max(diff_res)\n",
    "        ret['min_diff_lx_'+col] = np.min(diff_res)\n",
    "        ret['skew_diff_lx_'+col] = stats.skew(diff_res)\n",
    "        ret['kurt_diff_lx_'+col] = stats.kurtosis(diff_res)\n",
    "        return ret\n",
    "    \n",
    "    t = train_data[['file_id', col]]\n",
    "    df = pd.merge(df, t.groupby('file_id')[col].apply(checknum).unstack().reset_index(), on=['file_id'], how='left')\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = get_lx(df_train, train_data, 'api')\n",
    "\n",
    "df_train = get_lx(df_train, train_data, 'return_value')\n",
    "\n",
    "df_train['nb_nan'] = df_train.isnull().sum(1)\n",
    "\n",
    "names = ['0', '1', 'pos', 'neg']\n",
    "for i in range(4):\n",
    "    for j in range(i+1, 4):\n",
    "        df_train['num_{}_{}_ret_val_ratio'.format(names[i], names[j])] = df_train['num_{}_ret_val'.format(names[i])] / df_train['num_{}_ret_val'.format(names[j])]\n",
    "        df_train['num_{}_{}_ret_val_gap'.format(names[i], names[j])] = df_train['num_{}_ret_val'.format(names[i])] - df_train['num_{}_ret_val'.format(names[j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('./feature/df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.api.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_common_apis = Counter(train_data.api).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('./input/most_common_apis.npy', most_common_apis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_apis_ratio_num(df, data):\n",
    "    t = data[['file_id', 'api']]\n",
    "    t['num'] = 1\n",
    "    t = t.groupby(['file_id', 'api']).agg('sum').reset_index()\n",
    "\n",
    "    def cal_api_ratio(x):\n",
    "        ret = pd.Series()\n",
    "        for api in most_common_apis:\n",
    "            api_name = api[0]\n",
    "            res = x[x['api'] == api_name]['num'].values\n",
    "            if len(res) > 0:\n",
    "                ret['{}_num'.format(api_name)] = res[0]\n",
    "            else:\n",
    "                ret['{}_num'.format(api_name)] = 0\n",
    "            ret['{}_ratio'.format(api_name)] = ret['{}_num'.format(api_name)] / len(x)\n",
    "        return ret\n",
    "\n",
    "    t = t.groupby('file_id').apply(cal_api_ratio).reset_index()\n",
    "    df = pd.merge(df, t, on='file_id', how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cluster/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_train = get_common_apis_ratio_num(df_train, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('./feature/df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF-特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tf_idf_v1(df_tr, df_te, tr_data, te_data):\n",
    "    # 只考虑调用顺序 不考虑返回值\n",
    "    tr = tr_data[['file_id', 'api']]\n",
    "    te = te_data[['file_id', 'api']]\n",
    "\n",
    "    def get_api_seq(x):\n",
    "        apis = x['api'].values\n",
    "        api_seq = ' '.join(apis)\n",
    "        api_seq += '.'\n",
    "        return api_seq\n",
    "\n",
    "    t1 = tr.groupby('file_id').apply(get_api_seq).reset_index().rename(columns={0:'api_text'})\n",
    "    t2 = te.groupby('file_id').apply(get_api_seq).reset_index().rename(columns={0:'api_text'})\n",
    "\n",
    "    feature_extraction = TfidfVectorizer().fit(np.concatenate([t1[\"api_text\"].values, t2[\"api_text\"].values]))\n",
    "    tr_tfidf_fea = feature_extraction.transform(t1[\"api_text\"].values)\n",
    "    te_tfidf_fea = feature_extraction.transform(t2[\"api_text\"].values)\n",
    "\n",
    "    df_tr = pd.concat([df_tr, pd.DataFrame(tr_tfidf_fea.toarray())], axis=1)\n",
    "    df_te = pd.concat([df_te, pd.DataFrame(te_tfidf_fea.toarray())], axis=1)\n",
    "    \n",
    "    rename = {}\n",
    "\n",
    "    for i in range(0, te_tfidf_fea.shape[1]):\n",
    "        rename[i] = 'v1_{}'.format(i)\n",
    "\n",
    "    df_tr.rename(columns=rename, inplace=True)\n",
    "    df_te.rename(columns=rename, inplace=True)\n",
    "\n",
    "    return df_tr, df_te\n",
    "\n",
    "df_train, df_test = get_tf_idf_v1(df_train, df_test, train_data, test_data)\n",
    "\n",
    "def get_tf_idf_v2(df_tr, df_te, tr_data, te_data):\n",
    "    tr = tr_data[['file_id', 'api', 'return_value']]\n",
    "    te = te_data[['file_id', 'api', 'return_value']]\n",
    "\n",
    "    tr['ret_val'] = ''\n",
    "    tr.loc[tr['return_value'] > 0, 'ret_val'] = 'pos'\n",
    "    tr.loc[tr['return_value'] < 0, 'ret_val'] = 'neg'\n",
    "    tr.loc[tr['return_value'] == 0, 'ret_val'] = 'zero'\n",
    "    \n",
    "    te['ret_val'] = ''\n",
    "    te.loc[te['return_value'] > 0, 'ret_val'] = 'pos'\n",
    "    te.loc[te['return_value'] < 0, 'ret_val'] = 'neg'\n",
    "    te.loc[te['return_value'] == 0, 'ret_val'] = 'zero'\n",
    "    \n",
    "    tr['api_ret_val'] = tr['api'] + tr['ret_val']\n",
    "    te['api_ret_val'] = te['api'] + te['ret_val']\n",
    "\n",
    "    t1 = tr[['file_id', 'api_ret_val']]\n",
    "    t2 = te[['file_id', 'api_ret_val']]\n",
    "\n",
    "    def get_api_ret_val_seq(x):\n",
    "        apis = x['api_ret_val'].values\n",
    "        api_seq = ' '.join(apis)\n",
    "        api_seq += '.'\n",
    "        return api_seq\n",
    "\n",
    "    t1 = t1.groupby('file_id').apply(get_api_ret_val_seq).reset_index().rename(columns={0:'api_ret_val_text'})\n",
    "    t2 = t2.groupby('file_id').apply(get_api_ret_val_seq).reset_index().rename(columns={0:'api_ret_val_text'})\n",
    "\n",
    "    feature_extraction = TfidfVectorizer().fit(np.concatenate([t1[\"api_ret_val_text\"].values, t2[\"api_ret_val_text\"].values]))\n",
    "    \n",
    "    tr_tfidf_fea = feature_extraction.transform(t1[\"api_ret_val_text\"].values)\n",
    "    te_tfidf_fea = feature_extraction.transform(t2[\"api_ret_val_text\"].values)\n",
    "\n",
    "    df_tr = pd.concat([df_tr, pd.DataFrame(tr_tfidf_fea.toarray())], axis=1)\n",
    "    df_te = pd.concat([df_te, pd.DataFrame(te_tfidf_fea.toarray())], axis=1)\n",
    "\n",
    "    rename = {}\n",
    "    for i in range(0, tr_tfidf_fea.shape[1]):\n",
    "        rename[i] = 'v2_{}'.format(i)\n",
    "\n",
    "    df_tr.rename(columns=rename, inplace=True)\n",
    "    df_te.rename(columns=rename, inplace=True)\n",
    "    \n",
    "    return df_tr, df_te\n",
    "\n",
    "df_train, df_test = get_tf_idf_v2(df_train, df_test, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "      <th>num_invoke</th>\n",
       "      <th>nunique_api</th>\n",
       "      <th>mean_num_api</th>\n",
       "      <th>max_num_api</th>\n",
       "      <th>min_num_api</th>\n",
       "      <th>var_num_api</th>\n",
       "      <th>skew_num_api</th>\n",
       "      <th>kurt_num_api</th>\n",
       "      <th>...</th>\n",
       "      <th>v2_613</th>\n",
       "      <th>v2_614</th>\n",
       "      <th>v2_615</th>\n",
       "      <th>v2_616</th>\n",
       "      <th>v2_617</th>\n",
       "      <th>v2_618</th>\n",
       "      <th>v2_619</th>\n",
       "      <th>v2_620</th>\n",
       "      <th>v2_621</th>\n",
       "      <th>v2_622</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>19</td>\n",
       "      <td>22.315789</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>708.672515</td>\n",
       "      <td>1.346982</td>\n",
       "      <td>1.368728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.352381</td>\n",
       "      <td>3.444457</td>\n",
       "      <td>8.277387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2800</td>\n",
       "      <td>65</td>\n",
       "      <td>43.076923</td>\n",
       "      <td>1128</td>\n",
       "      <td>1</td>\n",
       "      <td>37224.415865</td>\n",
       "      <td>5.516723</td>\n",
       "      <td>27.213945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6832</td>\n",
       "      <td>78</td>\n",
       "      <td>87.589744</td>\n",
       "      <td>2970</td>\n",
       "      <td>1</td>\n",
       "      <td>157324.063270</td>\n",
       "      <td>6.093128</td>\n",
       "      <td>37.151675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1053 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label  num_invoke  nunique_api  mean_num_api  max_num_api  \\\n",
       "0        0      0         424           19     22.315789           99   \n",
       "1        1      5           2            2      1.000000            1   \n",
       "2        2      5          34           15      2.266667           14   \n",
       "3        3      5        2800           65     43.076923         1128   \n",
       "4        4      5        6832           78     87.589744         2970   \n",
       "\n",
       "   min_num_api    var_num_api  skew_num_api  kurt_num_api    ...     v2_613  \\\n",
       "0            1     708.672515      1.346982      1.368728    ...        0.0   \n",
       "1            1       0.000000           NaN     -3.000000    ...        0.0   \n",
       "2            1      11.352381      3.444457      8.277387    ...        0.0   \n",
       "3            1   37224.415865      5.516723     27.213945    ...        0.0   \n",
       "4            1  157324.063270      6.093128     37.151675    ...        0.0   \n",
       "\n",
       "   v2_614  v2_615  v2_616  v2_617  v2_618  v2_619  v2_620  v2_621    v2_622  \n",
       "0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000  \n",
       "1     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000  \n",
       "2     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000  \n",
       "3     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.001445  \n",
       "4     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.001176  \n",
       "\n",
       "[5 rows x 1053 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "apis = list(set(list(train_data.api.unique())+list(test_data.api.unique())))\n",
    "\n",
    "enc = LabelEncoder().fit(apis)\n",
    "\n",
    "train_data['enc'] = enc.transform(train_data.api)\n",
    "\n",
    "test_data['enc'] = enc.transform(test_data.api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面这部分是DOC2VEC向量进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = t.enc.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/message.c:4294)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(data)]\n",
    "# model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = train_data[['file_id', 'api', 'tid']]\n",
    "\n",
    "def get_api_seq(x):\n",
    "    apis = x['api'].values\n",
    "    api_seq = ' '.join(apis)\n",
    "    api_seq += '.'\n",
    "    return api_seq\n",
    "\n",
    "tr = tr.groupby(['file_id', 'tid']).apply(get_api_seq).reset_index().rename(columns={0:'api_text'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "te = test_data[['file_id', 'api', 'tid']]\n",
    "te = te.groupby(['file_id', 'tid']).apply(get_api_seq).reset_index().rename(columns={0:'api_text'})\n",
    "\n",
    "api_text = np.concatenate([tr.api_text.values, te.api_text.values])\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(api_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents, dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=5, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vec = model.docvecs.vectors_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_tr = pd.DataFrame(doc_vec[:tr.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_te = pd.DataFrame(doc_vec[tr.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286825</td>\n",
       "      <td>0.048865</td>\n",
       "      <td>0.061761</td>\n",
       "      <td>0.240027</td>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.121270</td>\n",
       "      <td>-0.366017</td>\n",
       "      <td>-0.335975</td>\n",
       "      <td>-0.037499</td>\n",
       "      <td>0.155380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219750</td>\n",
       "      <td>0.148943</td>\n",
       "      <td>0.166747</td>\n",
       "      <td>0.239572</td>\n",
       "      <td>0.204719</td>\n",
       "      <td>-0.109604</td>\n",
       "      <td>0.102926</td>\n",
       "      <td>-0.176948</td>\n",
       "      <td>0.042451</td>\n",
       "      <td>0.066088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068430</td>\n",
       "      <td>0.022290</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.080728</td>\n",
       "      <td>-0.071591</td>\n",
       "      <td>0.042092</td>\n",
       "      <td>-0.098902</td>\n",
       "      <td>0.096299</td>\n",
       "      <td>0.109431</td>\n",
       "      <td>0.047816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069886</td>\n",
       "      <td>-0.206756</td>\n",
       "      <td>-0.064712</td>\n",
       "      <td>0.174847</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>-0.449290</td>\n",
       "      <td>-0.138474</td>\n",
       "      <td>0.140562</td>\n",
       "      <td>-0.480538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060655</td>\n",
       "      <td>0.086610</td>\n",
       "      <td>0.240330</td>\n",
       "      <td>0.025454</td>\n",
       "      <td>-0.204714</td>\n",
       "      <td>-0.009900</td>\n",
       "      <td>-0.128736</td>\n",
       "      <td>-0.023981</td>\n",
       "      <td>-0.046222</td>\n",
       "      <td>0.119856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>-0.170435</td>\n",
       "      <td>-0.151556</td>\n",
       "      <td>0.054949</td>\n",
       "      <td>-0.068943</td>\n",
       "      <td>-0.047964</td>\n",
       "      <td>-0.165054</td>\n",
       "      <td>-0.123121</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>-0.181039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.142252</td>\n",
       "      <td>-0.216748</td>\n",
       "      <td>-0.273913</td>\n",
       "      <td>-0.015159</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>-0.163560</td>\n",
       "      <td>-0.111762</td>\n",
       "      <td>0.292721</td>\n",
       "      <td>-0.108130</td>\n",
       "      <td>0.326766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271479</td>\n",
       "      <td>-0.114769</td>\n",
       "      <td>0.382101</td>\n",
       "      <td>0.058515</td>\n",
       "      <td>-0.121215</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.618075</td>\n",
       "      <td>0.234555</td>\n",
       "      <td>0.010397</td>\n",
       "      <td>-0.334225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302964</td>\n",
       "      <td>0.050127</td>\n",
       "      <td>-0.056714</td>\n",
       "      <td>0.102139</td>\n",
       "      <td>-0.173627</td>\n",
       "      <td>0.046486</td>\n",
       "      <td>-0.039381</td>\n",
       "      <td>-0.070086</td>\n",
       "      <td>-0.076590</td>\n",
       "      <td>0.035541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061222</td>\n",
       "      <td>0.032373</td>\n",
       "      <td>-0.010070</td>\n",
       "      <td>-0.014053</td>\n",
       "      <td>0.064482</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.312032</td>\n",
       "      <td>-0.127941</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>-0.025358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.286825  0.048865  0.061761  0.240027 -0.190398  0.121270 -0.366017   \n",
       "1  0.068430  0.022290  0.037476  0.080728 -0.071591  0.042092 -0.098902   \n",
       "2  0.060655  0.086610  0.240330  0.025454 -0.204714 -0.009900 -0.128736   \n",
       "3  0.142252 -0.216748 -0.273913 -0.015159  0.001272 -0.163560 -0.111762   \n",
       "4  0.302964  0.050127 -0.056714  0.102139 -0.173627  0.046486 -0.039381   \n",
       "\n",
       "         7         8         9     ...           90        91        92  \\\n",
       "0 -0.335975 -0.037499  0.155380    ...    -0.219750  0.148943  0.166747   \n",
       "1  0.096299  0.109431  0.047816    ...     0.069886 -0.206756 -0.064712   \n",
       "2 -0.023981 -0.046222  0.119856    ...     0.039363 -0.170435 -0.151556   \n",
       "3  0.292721 -0.108130  0.326766    ...     0.271479 -0.114769  0.382101   \n",
       "4 -0.070086 -0.076590  0.035541    ...    -0.061222  0.032373 -0.010070   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0  0.239572  0.204719 -0.109604  0.102926 -0.176948  0.042451  0.066088  \n",
       "1  0.174847  0.037625  0.106167 -0.449290 -0.138474  0.140562 -0.480538  \n",
       "2  0.054949 -0.068943 -0.047964 -0.165054 -0.123121 -0.012198 -0.181039  \n",
       "3  0.058515 -0.121215 -0.005351 -0.618075  0.234555  0.010397 -0.334225  \n",
       "4 -0.014053  0.064482  0.093705 -0.312032 -0.127941  0.036302 -0.025358  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename_dict = {}\n",
    "for i in range(100):\n",
    "    rename_dict[i] = 'doc_{}'.format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_tr.rename(columns=rename_dict, inplace=True)\n",
    "doc_te.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = kmeans.fit_predict(doc_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmens聚类 类别为6 稍微提升"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr['classes'] = classes[:tr.shape[0]]\n",
    "\n",
    "te['classes'] = classes[tr.shape[0]: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_kmeans_fea(df, data):\n",
    "    # 获取聚类后的统计特征\n",
    "    t = data[['file_id', 'classes']]\n",
    "\n",
    "    t = t.groupby(['file_id', 'classes']).size().reset_index()\n",
    "\n",
    "    t.rename(columns={0: 'num'}, inplace=True)\n",
    "\n",
    "    # 出现次数最多\n",
    "    t1 = t.groupby('file_id').apply(lambda x: x['classes'].values[np.argsort(x['num'].values)[-1]]).reset_index().rename(columns={0: 'most_common_classes'})\n",
    "    df = pd.merge(df, t1, on=['file_id'], how='left')\n",
    "    \n",
    "    for i in range(6):\n",
    "        t = data[data.classes == i][['file_id', 'classes']]\n",
    "        \n",
    "        t = t.groupby(['file_id']).size().reset_index().rename(columns={0:'classes_{}_num'.format(i)})\n",
    "        \n",
    "        df = pd.merge(df, t, on='file_id', how='left')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = get_kmeans_fea(df_train, tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kmeans_ratio(df):\n",
    "    #获取比例\n",
    "    for i in range(6):\n",
    "        df['classes_{}_ratio'.format(i)] = df['classes_{}_num'.format(i)] / df['nunique_tid']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = get_kmeans_ratio(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = get_kmeans_fea(df_test, te)\n",
    "df_test = get_kmeans_ratio(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.to_csv('feature/df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('feature/df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LGB 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train[cols], label, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': {'multi_logloss'},\n",
    "    'num_class': 6,\n",
    "  'bagging_fraction': 0.8,\n",
    "  'feature_fraction': 0.6,\n",
    "  'nthread': 4,\n",
    "  'lambda_l1': 1,\n",
    "  'lambda_l2': 1\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=40000,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=50,\n",
    "                verbose_eval=10,\n",
    "                )\n",
    "\n",
    "# Training until validation scores don't improve for 50 rounds.\n",
    "# [10]\tvalid_0's multi_logloss: 0.518999\n",
    "# [20]\tvalid_0's multi_logloss: 0.203948\n",
    "# [30]\tvalid_0's multi_logloss: 0.0937345\n",
    "# [40]\tvalid_0's multi_logloss: 0.0523663\n",
    "# [50]\tvalid_0's multi_logloss: 0.0360914\n",
    "# [60]\tvalid_0's multi_logloss: 0.0291886\n",
    "# [70]\tvalid_0's multi_logloss: 0.0255474\n",
    "# [80]\tvalid_0's multi_logloss: 0.0239712\n",
    "# [90]\tvalid_0's multi_logloss: 0.023102\n",
    "# [100]\tvalid_0's multi_logloss: 0.0226112\n",
    "# [110]\tvalid_0's multi_logloss: 0.0224444\n",
    "# [120]\tvalid_0's multi_logloss: 0.0223155\n",
    "# [130]\tvalid_0's multi_logloss: 0.0223462\n",
    "# [140]\tvalid_0's multi_logloss: 0.0225303\n",
    "# [150]\tvalid_0's multi_logloss: 0.0226152\n",
    "# [160]\tvalid_0's multi_logloss: 0.0226824\n",
    "# [170]\tvalid_0's multi_logloss: 0.0227195\n",
    "# Early stopping, best iteration is:\n",
    "# [122]\tvalid_0's multi_logloss: 0.0222961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_val[cols])\n",
    "\n",
    "np.save('y_pred_lgb_0222961.npy', y_pred)\n",
    "\n",
    "y_sub = gbm.predict(df_test[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('input/3rd_security_submit_sample.csv')\n",
    "\n",
    "sub.loc[:, ['prob0','prob1','prob2','prob3','prob4','prob5']] = y_sub\n",
    "\n",
    "sub = sub.round(7)\n",
    "\n",
    "sub['sum'] = sub[['prob0','prob1','prob2','prob3','prob4','prob5']].sum(1)\n",
    "\n",
    "sub['prob0'] = sub['prob0'] / sub['sum']\n",
    "sub['prob1'] = sub['prob1'] / sub['sum']\n",
    "sub['prob2'] = sub['prob2'] / sub['sum']\n",
    "sub['prob3'] = sub['prob3'] / sub['sum']\n",
    "sub['prob4'] = sub['prob4'] / sub['sum']\n",
    "sub['prob5'] = sub['prob5'] / sub['sum']\n",
    "\n",
    "sub.head()\n",
    "\n",
    "sub[(sub[['prob0','prob1','prob2','prob3','prob4','prob5']].sum(1) - 1) >= 1e-6]\n",
    "\n",
    "sub[['file_id', 'prob0','prob1','prob2','prob3','prob4','prob5']].to_csv('lgb_0222961.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
